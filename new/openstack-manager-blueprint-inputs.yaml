#############################
# Provider specific Inputs
#############################

# Credentails and identification in order to connect to openstack
#keystone_username: ''
#keystone_password: ''
#keystone_tenant_name: ''
#keystone_url: ''
#region: ''

# Optional. Use this in order to override the default URLs provided by the keystone_url
#nova_url: ''
#neutron_url: ''

# The bootstrap process creates 2 key pairs in order to connect to the management machine and application hosts.
# Set these properties to true (one or both) if you want to use existing key pairs, and not create new ones.
#use_existing_manager_keypair: false
#use_existing_agent_keypair: false

# These are the local paths where the key files will be created at bootstrap.
# If existing key pairs are used (see above), the key files should be at these paths for cloudify to find.
#ssh_key_filename: ~/.ssh/cloudify-manager-kp.pem
#agent_private_key_path: ~/.ssh/cloudify-agent-kp.pem

# These are the key names in openstack that will be created at bootstrap.
# If existing key pairs are used (see above), bootstrap will use the provided names, and will not create new ones.
#manager_public_key_name: ''
#agent_public_key_name: ''

# Image and flavor that will be used to create the manager machine.
#image_id: ''
#flavor_id: ''

# Name of the external openstack network
#external_network_name: ''

# SSH user used to connect to the manager
#ssh_user: centos

# Names of the openstack components
#manager_server_name: cloudify-manager-server
#management_network_name: cloudify-management-network
#management_subnet_name: cloudify-management-network-subnet
#management_router: cloudify-management-router
#manager_security_group_name: cloudify-sg-manager
#agents_security_group_name: cloudify-sg-agents
#manager_port_name: cloudify-manager-port

# Optional prefix for each openstack component
#resources_prefix: ''

# This is the default user that the manager will use while connecting to an application host.
# This user can be overriden in different places.
#agents_user: ''

#############################
# Security Settings
#############################
# Username and password to be used for login, if the simple userstore implementation is used.
#username: 'admin'
#password: 'admin'

#############################
# Agent Packages
#############################

# The key names must be in the format: distro_release_agent (e.g. ubuntu_trusty_agent)
# as the key is what's used to name the file, which later allows our
# agent installer to identify it for your distro and release automatically.
# Note that the windows agent key name MUST be `cloudify_windows_agent`
#agent_package_urls:
#   ubuntu_trusty_agent: https://gigaspaces-repository-eu.s3.amazonaws.com/org/cloudify3/3.3.0/m6-RELEASE/Ubuntu-trusty-agent_3.3.0-m6-b276.tar.gz
#   ubuntu_precise_agent: https://gigaspaces-repository-eu.s3.amazonaws.com/org/cloudify3/3.3.0/m6-RELEASE/Ubuntu-precise-agent_3.3.0-m6-b276.tar.gz
#   centos_7x_agent: https://gigaspaces-repository-eu.s3.amazonaws.com/org/cloudify3/3.3.0/m6-RELEASE/centos-Core-agent_3.3.0-m6-b276.tar.gz
#   centos_6x_agent: https://gigaspaces-repository-eu.s3.amazonaws.com/org/cloudify3/3.3.0/m6-RELEASE/centos-Final-agent_3.3.0-m6-b276.tar.gz
#   cloudify_windows_agent: https://gigaspaces-repository-eu.s3.amazonaws.com/org/cloudify3/3.3.0/m6-RELEASE/cloudify-windows-agent_3.3.0-m6-b276.exe

#############################
# Cloudify Modules
#############################

# Note that you can replace rpm urls with names of packages as long as they're available in your default yum repository.
# That is, as long as they provide the exact same version of that module.

#rest_service_rpm_url: https://gigaspaces-repository-eu.s3.amazonaws.com/org/cloudify3/3.3.0/m6-RELEASE/cloudify-rest-service-3.3.0-m6_b276.x86_64.rpm
#management_worker_rpm_source_url: https://gigaspaces-repository-eu.s3.amazonaws.com/org/cloudify3/3.3.0/m6-RELEASE/cloudify-management-worker-3.3.0-m6_b276.x86_64.rpm
#amqpinflux_rpm_source_url: https://gigaspaces-repository-eu.s3.amazonaws.com/org/cloudify3/3.3.0/m6-RELEASE/cloudify-amqp-influx-3.3.0-m6_b276.x86_64.rpm
#cloudify_resources_url: https://github.com/cloudify-cosmo/cloudify-manager/archive/master.tar.gz
#webui_source_url: https://gigaspaces-repository-eu.s3.amazonaws.com/org/cloudify3/3.3.0/m6-RELEASE/cloudify-ui-3.3.0-m6-b276.tgz
# This is a Cloudify specific redistribution of Grafana.
#grafana_source_url: http://gigaspaces-repository-eu.s3.amazonaws.com/org/cloudify3/components/grafana-1.9.0.tgz

#############################
# External Components
#############################

# Note that you can replace rpm urls with names of packages as long as they're available in your default yum repository.
# That is, as long as they provide the exact same version of that module.

#pip_source_rpm_url: https://gigaspaces-repository-eu.s3.amazonaws.com/org/cloudify3/components/python-pip-7.1.0-1.el7.noarch.rpm
#java_source_url: https://gigaspaces-repository-eu.s3.amazonaws.com/org/cloudify3/components/jre1.8.0_45-1.8.0_45-fcs.x86_64.rpm

# RabbitMQ Distribution of Erlang
#erlang_source_url: https://gigaspaces-repository-eu.s3.amazonaws.com/org/cloudify3/components/erlang-17.4-1.el6.x86_64.rpm
#rabbitmq_source_url: https://gigaspaces-repository-eu.s3.amazonaws.com/org/cloudify3/components/rabbitmq-server-3.5.3-1.noarch.rpm

#elasticsearch_source_url: https://gigaspaces-repository-eu.s3.amazonaws.com/org/cloudify3/components/elasticsearch-1.6.0.noarch.rpm
#elasticsearch_curator_rpm_source_url: https://gigaspaces-repository-eu.s3.amazonaws.com/org/cloudify3/components/elasticsearch-curator-3.2.3-1.x86_64.rpm

#logstash_source_url: https://gigaspaces-repository-eu.s3.amazonaws.com/org/cloudify3/components/logstash-1.5.0-1.noarch.rpm
#nginx_source_url: https://gigaspaces-repository-eu.s3.amazonaws.com/org/cloudify3/components/nginx-1.8.0-1.el7.ngx.x86_64.rpm
#influxdb_source_url: https://gigaspaces-repository-eu.s3.amazonaws.com/org/cloudify3/components/influxdb-0.8.8-1.x86_64.rpm

#riemann_source_url: https://gigaspaces-repository-eu.s3.amazonaws.com/org/cloudify3/components/riemann-0.2.6-1.noarch.rpm
# A RabbitMQ Client for Riemann
#langohr_source_url: https://gigaspaces-repository-eu.s3.amazonaws.com/org/cloudify3/components/langohr.jar
# Riemann's default daemonizer
#daemonize_source_url: https://gigaspaces-repository-eu.s3.amazonaws.com/org/cloudify3/components/daemonize-1.7.3-7.el7.x86_64.rpm

#nodejs_source_url: https://gigaspaces-repository-eu.s3.amazonaws.com/org/cloudify3/components/node-v0.10.35-linux-x64.tar.gz

#############################
# RabbitMQ Configuration
#############################
# Allows defining the message-ttl for the different types of queues (in milliseconds).
# https://www.rabbitmq.com/ttl.html
#rabbitmq_events_queue_message_ttl: 60000
#rabbitmq_logs_queue_message_ttl: 60000
#rabbitmq_metrics_queue_message_ttl: 60000

# note that for each of the queue length limit properties, new messages
# will be queued in RabbitMQ and old messages will be deleted once the
# limit is reached!
# Note this is NOT the message byte length!
# https://www.rabbitmq.com/maxlength.html
#rabbitmq_events_queue_length_limit: 1000000
#rabbitmq_logs_queue_length_limit: 1000000
#rabbitmq_metrics_queue_length_limit: 1000000

# RabbitMQ File Descriptors Limit
#rabbitmq_fd_limit: 102400

#############################
# Elasticsearch Configuration
#############################
# https://www.elastic.co/guide/en/elasticsearch/guide/current/heap-sizing.html
#elasticsearch_heap_size: 2g

# This allows to provide any JAVA_OPTS to Elasticsearch.
#elasticsearch_java_opts: ''

# The index for events will be named `logstash-YYYY.mm.dd`.
# A new index corresponding with today's date will be added each day.
# Elasticsearch Curator is used to rotate the indices on a daily basis
# via a cronjob. This allows to determine the number of days to keep.
#elasticsearch_index_rotation_interval: 7

# You can configure an external endpoint of an Elasticsearch Cluster to use
# instead of the built in one. The built in Elasticsearch cluster will not run.
# You need to provide an IP (defaults to localhost) and Port (defaults to 9200) of your Elasticsearch Cluster.
#elasticsearch_endpoint_ip: ''
#elasticsearch_endpoint_port: 9200

#############################
# InfluxDB Configuration
#############################
# You can configure an external endpoint of an InfluxDB Cluster to use
# instead of the built in one.
# If one is provided, the built in InfluxDB cluster will not run.
# Note that the port is currently not configurable and must remain 8086.
# Also note that the database username and password are hardcoded to root:root.
#influxdb_endpoint_ip: ''
