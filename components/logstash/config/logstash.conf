# Note that localhost is assumed both for RabbitMQ by default and Elasticsearch
# and should be replaced using a relationship operation if they're not on the same host.

# We provide 2 inputs, one for events and one for logs.
# Currently, we index both events and logs in one Elasticsearch index but this will change in the future.
input {
    rabbitmq {
        queue => "cloudify-logs"
        exchange => "cloudify-logs"
        host => "{{ ctx.instance.runtime_properties.rabbitmq_endpoint_ip }}"
        port => "5672"
        durable => "true"
        auto_delete => "true"
        exclusive => "false"
        user => "{{ ctx.instance.runtime_properties.rabbitmq_username }}"
        password => "{{ ctx.instance.runtime_properties.rabbitmq_password }}"
    }
    rabbitmq {
        queue => "cloudify-events"
        exchange => "cloudify-events"
        host => "{{ ctx.instance.runtime_properties.rabbitmq_endpoint_ip }}"
        port => "5672"
        durable => "true"
        auto_delete => "true"
        exclusive => "false"
        user => "{{ ctx.instance.runtime_properties.rabbitmq_username }}"
        password => "{{ ctx.instance.runtime_properties.rabbitmq_password }}"
    }
    # This allows us to verify that logstash is running.
    # it is non-functional for the manager and will be removed in the future.
    tcp {
        port => "9999"
    }
}

# This allows us to reformat the events/logs timestamps to the current manager time
# This is meant to overcome timing issues with events coming in late or getting stuck in the queue.
# It is only a temporary solution.
filter {
    date { match => [ "timestamp", "ISO8601" ] }
}


output {
    elasticsearch_http {
        host => "{{ ctx.instance.runtime_properties.es_endpoint_ip }}"
        port => "{{ ctx.instance.runtime_properties.es_endpoint_port }}"
    }
}
